{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYmdL3l-2eOF"
      },
      "source": [
        "# Enviornment setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F73P8q4h2h7_"
      },
      "source": [
        "The goal of this first partical is to verify that your environment is correctly set up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuMG_5ltBlgA"
      },
      "source": [
        "## Import package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEx8c5BPBozE"
      },
      "source": [
        "It is good practice to import all necessary packages at the top of Python files or in the first code cell of a Python notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8J0mnBAqB34I"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/media/jgaspar/7CCE3FA7CE3F589A1/MCS/1_Semester/ai/ai-security-labs/src/01_environment_setup/.venv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import sklearn\n",
        "import mlc\n",
        "from mlc.datasets.dataset_factory import get_dataset\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS2FtrBvB7mO"
      },
      "source": [
        "We check the correct version are installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqYf3po7B-nl",
        "outputId": "7e5bc191-944b-46a2-921f-5566727dc027"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OK: torch==1.12.1+cu102.\n",
            "OK: sklearn==1.2.1.\n",
            "OK: mlc==0.1.0.\n"
          ]
        }
      ],
      "source": [
        "for pkg, version in [(torch, \"1.12.1\"), (sklearn, \"1.2.1\"), (mlc, \"0.1.0\")]:\n",
        "    if version in pkg.__version__:\n",
        "        print(f\"OK: {pkg.__name__}=={pkg.__version__}.\")\n",
        "    else:\n",
        "        print(f\"Version mismatch: expected version {version} for package {pkg.__name__} but is currently {pkg.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THKn2-vlGC2H"
      },
      "source": [
        "## Retrieve data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUc64rNzGCZi"
      },
      "source": [
        "In this section we will download and load a feature engineered version of the popular Lending Club Loan Data dataset ([LCLD](https://www.kaggle.com/datasets/wordsforthewise/lending-club))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WIhkHObkDkEY"
      },
      "outputs": [],
      "source": [
        "dataset = get_dataset(\"lcld_v2_iid\")\n",
        "x, y = dataset.get_x_y()\n",
        "metadata = dataset.get_metadata(only_x=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r9xERyggHHiN"
      },
      "outputs": [],
      "source": [
        "# Splitting the data\n",
        "splits = dataset.get_splits()\n",
        "x_train, x_val, x_test = x.iloc[splits[\"train\"]], x.iloc[splits[\"val\"]], x.iloc[splits[\"test\"]]\n",
        "y_train, y_val, y_test = y[splits[\"train\"]], y[splits[\"val\"]], y[splits[\"test\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4eHpDwGdIOZl"
      },
      "outputs": [],
      "source": [
        "# Scaling the data, the metadata contains for each feature, its name (feature) and its type (type).\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', MinMaxScaler(), metadata[metadata[\"type\"] != \"cat\"][\"feature\"]),\n",
        "        ('cat', OneHotEncoder(), metadata[metadata[\"type\"] == \"cat\"][\"feature\"])\n",
        "    ])\n",
        "\n",
        "preprocessor.fit(x)\n",
        "x_train = preprocessor.transform(x_train)\n",
        "x_val =  preprocessor.transform(x_val)\n",
        "x_test =  preprocessor.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOWkJM7DJce8"
      },
      "source": [
        "## Fit sklearn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "SW5-a3pMJiuE",
        "outputId": "c77f1c12-21ef-4dee-f681-6d4c789ec623"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 12 concurrent workers.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "building tree 1 of 10\n",
            "building tree 2 of 10\n",
            "building tree 3 of 10\n",
            "building tree 4 of 10\n",
            "building tree 5 of 10\n",
            "building tree 6 of 10\n",
            "building tree 7 of 10\n",
            "building tree 8 of 10\n",
            "building tree 9 of 10\n",
            "building tree 10 of 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    2.2s remaining:    2.2s\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    2.4s finished\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=10, n_jobs=-1,\n",
              "                       verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, n_estimators=10, n_jobs=-1,\n",
              "                       verbose=2)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(class_weight='balanced', n_estimators=10, n_jobs=-1,\n",
              "                       verbose=2)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = RandomForestClassifier(n_estimators=10, class_weight=\"balanced\", n_jobs=-1, verbose=2)\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjd4GYbBKJIM",
        "outputId": "c1802352-6f79-4c73-a91d-2f932709d7c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=10)]: Using backend ThreadingBackend with 10 concurrent workers.\n",
            "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:    0.4s remaining:    0.9s\n",
            "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:    0.4s finished\n"
          ]
        }
      ],
      "source": [
        "# Model prediction\n",
        "y_score = model.predict_proba(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKJHSEzsLWjl",
        "outputId": "836d03d4-17c5-4280-968a-197cab4b77a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The AUROC score of the model is 0.650728917611888\n"
          ]
        }
      ],
      "source": [
        "# Model scoring\n",
        "auc = roc_auc_score(y_test, y_score[:, 1])\n",
        "print(f\"The AUROC score of the model is {auc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tGKSYt1MdAt",
        "outputId": "b844f5ac-a2a6-4069-98c3-38e6924b687e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(494088, 50)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s17YY5NTMJy7"
      },
      "source": [
        "## Fit torch Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XLNFcuMQMPNR"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.l1 = nn.Linear(50, 64)\n",
        "        self.l2 = nn.Linear(64, 32)\n",
        "        self.l3 = nn.Linear(32, 16)\n",
        "        self.l4 = nn.Linear(16, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.l4(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1l_W-v-NAh6",
        "outputId": "690cb589-e140-4223-bbde-05be4d5e4907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class weight tensor([0.2009, 0.7991])\n"
          ]
        }
      ],
      "source": [
        "class_weight = torch.Tensor(\n",
        "    1 - torch.unique(torch.tensor(y_train), return_counts=True)[1] / len(y_train)\n",
        ")\n",
        "print(f\"Class weight {class_weight}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rnlkZp7jNT66"
      },
      "outputs": [],
      "source": [
        "model = Net()\n",
        "optimizer = optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6jcAdcVkNsYF"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, batch_size):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in tqdm(enumerate(dataloader), total=int(size/batch_size)):\n",
        "        # if batch % 10 == 0:\n",
        "        #     print(f\"Batch {batch}.\")\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def val_loop(dataloader, model, loss_fn, epoch_i):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y[:, 1]).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Epoch {epoch_i}, Val Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, x_train, y_train, x_val, y_val, optimizer, batch_size, loss_func, epochs):\n",
        "    # Data processing\n",
        "    train_dataset = TensorDataset(x_train, y_train)\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "    )\n",
        "    val_dataset = TensorDataset(x_val, y_val)\n",
        "    val_loader = DataLoader(\n",
        "        dataset=val_dataset,\n",
        "        batch_size=2000,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "    )\n",
        "\n",
        "    # Main train loop\n",
        "    for epoch in range(epochs):\n",
        "        train_loop(train_loader, model, loss_func, optimizer, batch_size)\n",
        "        val_loop(val_loader, model, loss_func, epoch)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_YHuRh7ONOR",
        "outputId": "98fcf61b-77aa-4915-f559-362099d97a5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "483it [00:02, 200.60it/s]                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Val Error: Accuracy: 70.2%, Avg loss: 0.200828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "483it [00:02, 234.66it/s]                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Val Error: Accuracy: 65.9%, Avg loss: 0.199612\n"
          ]
        }
      ],
      "source": [
        "loss = nn.CrossEntropyLoss(weight=class_weight)\n",
        "train_model(\n",
        "    model,\n",
        "    torch.from_numpy(x_train).float(),\n",
        "    torch.from_numpy(np.array([1 - y_train, y_train]).T).float(),\n",
        "    torch.from_numpy(x_val).float(),\n",
        "    torch.from_numpy(np.array([1 - y_val, y_val]).T).float(),\n",
        "    optimizer,\n",
        "    1024,\n",
        "    loss,\n",
        "    2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9EZlIo6JO92l"
      },
      "outputs": [],
      "source": [
        "# Model prediction\n",
        "y_score = model(torch.from_numpy(x_test).float()).detach().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEd7pTvsQ7-b",
        "outputId": "c411d0a4-3b32-478c-9a75-5730a5758d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The AUROC score of the model is 0.7125688608134522\n"
          ]
        }
      ],
      "source": [
        "# Model scoring\n",
        "auc = roc_auc_score(y_test, y_score[:, 1])\n",
        "print(f\"The AUROC score of the model is {auc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXBeQHOXRGO_"
      },
      "source": [
        "## Future practical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpyZrMcDRHHe"
      },
      "source": [
        "If you reach this section without trouble, you should be able to complete future practicals.\n",
        "Simply open the folder of the other practicals in VSCode, install the dependencies with `uv sync`, and select the correct Python interpreter.\n",
        "\n",
        "If any questions remain to setup your environment, do not hesitate to contact the teaching team."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "01-environment-setup",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
