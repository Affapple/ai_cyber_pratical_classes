{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYmdL3l-2eOF"
      },
      "source": [
        "# Enviornment setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F73P8q4h2h7_"
      },
      "source": [
        "The goal of this first partical is to setup the environment.\n",
        "To start, we will use colab to be sure you can execute notebooks and complete future practicals.\n",
        "Then we will go through the installation of a Python environment on your local machine."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwBFMuVB3ET-"
      },
      "source": [
        "## Install dependencies (Colab Only)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0DoFis23IsJ"
      },
      "source": [
        "Installing dependencies allows you to reuse tools, libraries and framework created by others.\n",
        "The most used dependencies manager in Python is pip. Pip is a command line tool that pull dependencies from a repository . The repository is often the centralized https://pypi.org/, but can also be the private repository of a company.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDxhiyI7-8UT"
      },
      "source": [
        "In the next cell, we will install common dependencies that you will need in future practicals. The list of dependencies is located in `requirements.txt` by convention. (Focus the cell and execute it by pressing `ctrl + enter`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMMkSzNV3HTc",
        "outputId": "63072e88-274f-4cfd-cc10-4982f9014e21"
      },
      "outputs": [],
      "source": [
        "%pip install -r /content/drive/MyDrive/cyberus_ml_security/0_environment_setup/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuMG_5ltBlgA"
      },
      "source": [
        "## Import package"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEx8c5BPBozE"
      },
      "source": [
        "It is good practice to import all necessary packages at the top of Python files or in the first code cell of a Python notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8J0mnBAqB34I"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sklearn\n",
        "import mlc\n",
        "from mlc.datasets.dataset_factory import get_dataset\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS2FtrBvB7mO"
      },
      "source": [
        "We check the correct version are installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqYf3po7B-nl",
        "outputId": "7e5bc191-944b-46a2-921f-5566727dc027"
      },
      "outputs": [],
      "source": [
        "for pkg, version in [(torch, \"1.12.1\"), (sklearn, \"1.2.1\"), (mlc, \"0.1.0\")]:\n",
        "    if version in pkg.__version__:\n",
        "        print(f\"OK: {pkg.__name__}=={pkg.__version__}.\")\n",
        "    else:\n",
        "        print(f\"Version mismatch: expected version {version} for package {pkg.__name__} but is currently {pkg.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THKn2-vlGC2H"
      },
      "source": [
        "## Retrieve data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUc64rNzGCZi"
      },
      "source": [
        "In this section we will download and load a feature engineered version of the popular Lending Club Loan Data dataset ([LCLD](https://www.kaggle.com/datasets/wordsforthewise/lending-club))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIhkHObkDkEY"
      },
      "outputs": [],
      "source": [
        "dataset = get_dataset(\"lcld_v2_iid\")\n",
        "x, y = dataset.get_x_y()\n",
        "metadata = dataset.get_metadata(only_x=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9xERyggHHiN"
      },
      "outputs": [],
      "source": [
        "# Splitting the data\n",
        "splits = dataset.get_splits()\n",
        "x_train, x_val, x_test = x.iloc[splits[\"train\"]], x.iloc[splits[\"val\"]], x.iloc[splits[\"test\"]]\n",
        "y_train, y_val, y_test = y[splits[\"train\"]], y[splits[\"val\"]], y[splits[\"test\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4eHpDwGdIOZl"
      },
      "outputs": [],
      "source": [
        "# Scaling the data, the metadata contains for each feature, its name (feature) and its type (type).\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', MinMaxScaler(), metadata[metadata[\"type\"] != \"cat\"][\"feature\"]),\n",
        "        ('cat', OneHotEncoder(), metadata[metadata[\"type\"] == \"cat\"][\"feature\"])\n",
        "    ])\n",
        "\n",
        "preprocessor.fit(x)\n",
        "x_train = preprocessor.transform(x_train)\n",
        "x_val =  preprocessor.transform(x_val)\n",
        "x_test =  preprocessor.transform(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOWkJM7DJce8"
      },
      "source": [
        "## Fit sklearn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "SW5-a3pMJiuE",
        "outputId": "c77f1c12-21ef-4dee-f681-6d4c789ec623"
      },
      "outputs": [],
      "source": [
        "model = RandomForestClassifier(n_estimators=10, class_weight=\"balanced\", n_jobs=-1, verbose=2)\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjd4GYbBKJIM",
        "outputId": "c1802352-6f79-4c73-a91d-2f932709d7c7"
      },
      "outputs": [],
      "source": [
        "# Model prediction\n",
        "y_score = model.predict_proba(x_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKJHSEzsLWjl",
        "outputId": "836d03d4-17c5-4280-968a-197cab4b77a2"
      },
      "outputs": [],
      "source": [
        "# Model scoring\n",
        "auc = roc_auc_score(y_test, y_score[:, 1])\n",
        "print(f\"The AUROC score of the model is {auc}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tGKSYt1MdAt",
        "outputId": "b844f5ac-a2a6-4069-98c3-38e6924b687e"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s17YY5NTMJy7"
      },
      "source": [
        "## Fit torch Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLNFcuMQMPNR"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.l1 = nn.Linear(50, 64)\n",
        "        self.l2 = nn.Linear(64, 32)\n",
        "        self.l3 = nn.Linear(32, 16)\n",
        "        self.l4 = nn.Linear(16, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.l1(x)\n",
        "        x = self.l2(x)\n",
        "        x = self.l3(x)\n",
        "        x = self.l4(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1l_W-v-NAh6",
        "outputId": "690cb589-e140-4223-bbde-05be4d5e4907"
      },
      "outputs": [],
      "source": [
        "class_weight = torch.Tensor(\n",
        "    1 - torch.unique(torch.tensor(y_train), return_counts=True)[1] / len(y_train)\n",
        ")\n",
        "print(f\"Class weight {class_weight}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnlkZp7jNT66"
      },
      "outputs": [],
      "source": [
        "model = Net()\n",
        "optimizer = optim.AdamW(\n",
        "    filter(lambda p: p.requires_grad, model.parameters()),\n",
        "    lr=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jcAdcVkNsYF"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer, batch_size):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in tqdm(enumerate(dataloader), total=int(size/batch_size)):\n",
        "        # if batch % 10 == 0:\n",
        "        #     print(f\"Batch {batch}.\")\n",
        "        # Compute prediction and loss\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def val_loop(dataloader, model, loss_fn, epoch_i):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y[:, 1]).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Epoch {epoch_i}, Val Error: Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, x_train, y_train, x_val, y_val, optimizer, batch_size, loss_func, epochs):\n",
        "    # Data processing\n",
        "    train_dataset = TensorDataset(x_train, y_train)\n",
        "    train_loader = DataLoader(\n",
        "        dataset=train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "    )\n",
        "    val_dataset = TensorDataset(x_val, y_val)\n",
        "    val_loader = DataLoader(\n",
        "        dataset=val_dataset,\n",
        "        batch_size=2000,\n",
        "        shuffle=True,\n",
        "        num_workers=2,\n",
        "    )\n",
        "\n",
        "    # Main train loop\n",
        "    for epoch in range(epochs):\n",
        "        train_loop(train_loader, model, loss_func, optimizer, batch_size)\n",
        "        val_loop(val_loader, model, loss_func, epoch)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_YHuRh7ONOR",
        "outputId": "98fcf61b-77aa-4915-f559-362099d97a5a"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss(weight=class_weight)\n",
        "train_model(\n",
        "    model,\n",
        "    torch.from_numpy(x_train).float(),\n",
        "    torch.from_numpy(np.array([1 - y_train, y_train]).T).float(),\n",
        "    torch.from_numpy(x_val).float(),\n",
        "    torch.from_numpy(np.array([1 - y_val, y_val]).T).float(),\n",
        "    optimizer,\n",
        "    1024,\n",
        "    loss,\n",
        "    2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EZlIo6JO92l"
      },
      "outputs": [],
      "source": [
        "# Model prediction\n",
        "y_score = model(torch.from_numpy(x_test).float()).detach().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEd7pTvsQ7-b",
        "outputId": "c411d0a4-3b32-478c-9a75-5730a5758d3b"
      },
      "outputs": [],
      "source": [
        "# Model scoring\n",
        "auc = roc_auc_score(y_test, y_score[:, 1])\n",
        "print(f\"The AUROC score of the model is {auc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXBeQHOXRGO_"
      },
      "source": [
        "## Future practical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpyZrMcDRHHe"
      },
      "source": [
        "If you reach this section without trouble, you should be able to complete future practicals.\n",
        "\n",
        "The list of dependencies in the requirements.txt file may be updated with each practical. If some packages do not import properly, your dependencies are probably outdated. Simply re-run `pip install -r requirements.txt`. If you are using a local environment, it is recommended to create a new conda environment for each practical.\n",
        "\n",
        "If any questions remain to setup your environment, do not hesitate to contact the teaching team."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
