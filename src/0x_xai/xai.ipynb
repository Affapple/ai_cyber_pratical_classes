{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a28e81e",
   "metadata": {},
   "source": [
    "# Explainability Lab\n",
    "**Date:** 2025-10-29\n",
    "\n",
    "**What this notebook covers**\n",
    "- Load & preprocess the UCI Adult dataset (via `fetch_openml`).\n",
    "- Train a Random Forest Classifier.\n",
    "- Generate and visualize feature attributions with **SHAP** and **Lime**.\n",
    "- Train a PyTorch MLP classifier.\n",
    "- Generate and visualize feature attributions using **Captum** gradient-based methods:\n",
    "  - Saliency\n",
    "  - SmoothGrad (NoiseTunnel)\n",
    "  - InputxGradients\n",
    "  - Integrated Gradients.\n",
    "- Generate and visualize feature attributions using **Zennit** LRP methods:\n",
    "  - LRP (Layer-wise Relevance Propagation).\n",
    "- Evaluate every XAI methods with **Quantus** metrics.\n",
    "- Implement a counterfactual generation for tabular data using **Dice**.\n",
    "\n",
    "> Notes:\n",
    "- This notebook expects an environment with internet to fetch the dataset and `captum` installed.\n",
    "- Install tips (if needed): `pip install captum lime shap zennit scikit-learn pandas matplotlib quantus`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425bb501",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623cf6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jky/ai-security-labs/src/0x_xai/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from captum.attr import (\n",
    "    Saliency,\n",
    "    IntegratedGradients,\n",
    "    NoiseTunnel,\n",
    "    InputXGradient,\n",
    ")\n",
    "\n",
    "from zennit.attribution import Gradient\n",
    "\n",
    "import quantus\n",
    "\n",
    "from typing import List, Callable, Dict, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)  # safe even if no GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd29ea21",
   "metadata": {},
   "source": [
    "## Load & Preprocess the Adult dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68680f3",
   "metadata": {},
   "source": [
    "In this section we:\n",
    "1. Download the UCI Adult dataset via OpenML.\n",
    "2. Clean basic missing values.\n",
    "3. Separate target vs features.\n",
    "4. Apply preprocessing (scaling numeric features, encoding categorical ones).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087c4f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Adult from OpenML\n",
    "adult = fetch_openml(name='adult', version=2, as_frame=True)\n",
    "df = adult.frame.copy()\n",
    "\n",
    "# Replace '?' with NaN and drop rows with missing (simple but aggressive approach).\n",
    "# In practice you may want something more subtle (imputation, etc.).\n",
    "df = df.replace('?', np.nan).dropna()\n",
    "\n",
    "# Target is 'class': '>50K' or '<=50K' —> convert to 0/1\n",
    "df['class'] = (df['class'] == '>50K').astype(int)\n",
    "\n",
    "# Identify categorical vs numeric columns\n",
    "target_col = 'class'\n",
    "X_df = df.drop(columns=[target_col])\n",
    "y = df[target_col].values\n",
    "\n",
    "# Identify categorical vs numeric columns (based on dtype).\n",
    "cat_cols = X_df.select_dtypes(include=['category','object']).columns.tolist()\n",
    "num_cols = [c for c in X_df.columns if c not in cat_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f8057f",
   "metadata": {},
   "source": [
    "Build preprocessing pipeline:\n",
    "- `StandardScaler` for numeric columns (zero mean, unit variance).\n",
    "- `OrdinalEncoder` for categorical columns.\n",
    "\n",
    "We **could** use `OneHotEncoder`, but that can create many sparse features.\n",
    "Here we use OrdinalEncoder to keep the feature space compact, which simplifies some XAI methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c302f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        # ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
    "        ('cat', OrdinalEncoder(), cat_cols), # We use here OrdinalEncoder to limit the number of features\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_processed = preprocess.fit_transform(X_df)\n",
    "\n",
    "# Store the feature names after preprocessing for later interpretation.\n",
    "feature_names_num = num_cols\n",
    "feature_names_cat = list(preprocess.named_transformers_['cat'].get_feature_names_out(cat_cols))\n",
    "feature_names_all = feature_names_num + feature_names_cat\n",
    "\n",
    "# Split into train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df57a660",
   "metadata": {},
   "source": [
    "We now convert the NumPy arrays to PyTorch tensors and build DataLoaders for the MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ff634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the torch tensors\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1,1)\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32).view(-1,1)\n",
    "\n",
    "if (y_train_t.ndim == 1) or (y_train_t.shape[1] == 1):\n",
    "    y_train_t = torch.column_stack((1 - y_train_t, y_train_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6954bd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap tensors into TensorDataset and DataLoader for batching.\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "test_ds = TensorDataset(X_test_t, y_test_t)\n",
    "train_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=256, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec773ac",
   "metadata": {},
   "source": [
    "## Scikit Learn Random Forest Model & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b4901d",
   "metadata": {},
   "source": [
    "We first train a classical `RandomForestClassifier` tree ensemble on the preprocessed features. This will be our baseline model for **SHAP** and **LIME** explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e17cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities and hard predictions on the test set.\n",
    "y_prob = rf.predict_proba(X_test)[:, 1]\n",
    "y_pred = rf.predict(X_test)\n",
    "#y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "print(\"ROC-AUC:\", round(roc_auc_score(y_test, y_prob), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64588008",
   "metadata": {},
   "source": [
    "### SHAP Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16df35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "# Explain the model's predictions using SHAP.\n",
    "# For tree-based models, SHAP can use highly optimized algorithms.\n",
    "explainer = shap.Explainer(rf, feature_names=feature_names_all)\n",
    "shap_values = explainer(X_test[:100]) # Explain first 100 test instances for time constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d86414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waterfall plot\n",
    "shap.plots.waterfall(shap_values[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818d8b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force plot\n",
    "shap.plots.force(shap_values[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314ac2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize all the explanations\n",
    "shap.plots.force(shap_values[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94ffbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm plot\n",
    "shap.plots.beeswarm(shap_values[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a946f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot\n",
    "shap.plots.bar(shap_values[:, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d51b83",
   "metadata": {},
   "source": [
    "### LIME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232b0c56",
   "metadata": {},
   "source": [
    "We now apply LIME to the same Random Forest model.\n",
    "LIME learns a local surrogate model around one specific input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbd30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# Note: here we pass `X_train` as the background data in the preprocessed space.\n",
    "explainer_lime = LimeTabularExplainer(\n",
    "    training_data=X_train,\n",
    "    feature_names=feature_names_all,\n",
    "    class_names=['<=50K','>50K'],\n",
    "    categorical_features=feature_names_cat,\n",
    "    discretize_continuous=True,\n",
    "    random_state=SEED)\n",
    "\n",
    "idx = 0 ## index of the test instance to explain\n",
    "x_raw = X_test[idx]\n",
    "exp = explainer_lime.explain_instance(\n",
    "    data_row=np.array(x_raw),\n",
    "    predict_fn=rf.predict_proba,\n",
    "    num_features=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e764558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatibility shim for LIME + modern IPython\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "html = exp.as_html()\n",
    "display(HTML(html))\n",
    "\n",
    "# # monkey-patch only if missing\n",
    "# if not hasattr(_icd, \"display\"):\n",
    "#     _icd.display = display\n",
    "# if not hasattr(_icd, \"HTML\"):\n",
    "#     _icd.HTML = HTML\n",
    "\n",
    "# exp.show_in_notebook(show_table=True, show_all=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0079670f",
   "metadata": {},
   "source": [
    "## PyTorch MLP Model & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89bf64c",
   "metadata": {},
   "source": [
    "We now build a simple fully-connected neural network for the same task,\n",
    "which we will then analyze using **Captum** and **Zennit**.\n",
    "\n",
    ">Note: this is not a highly tuned architecture; the goal is to have\n",
    "a reasonably accurate yet simple model, not to win Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple fully-connected MLP for tabular classification.\n",
    "\n",
    "    The network consists of:\n",
    "      - An input layer projecting from `input_dim` to `hidden_dim`.\n",
    "      - `n_layers - 1` hidden layers of size `hidden_dim` with ReLU activations.\n",
    "      - A final linear layer projecting to `output_dim` (number of classes).\n",
    "      - A softmax over the output to obtain class probabilities.\n",
    "\n",
    "    Args:\n",
    "        n_layers (int): Total number of linear layers (including output).\n",
    "        input_dim (int): Number of input features.\n",
    "        hidden_dim (int): Number of units in each hidden layer.\n",
    "        output_dim (int): Number of output classes.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_layers, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()     \n",
    "\n",
    "        layers = []\n",
    "\n",
    "        # Input Layer (= first hidden layer)\n",
    "        layers += [nn.Linear(input_dim, hidden_dim), nn.ReLU()]\n",
    "\n",
    "        # Hidden Layers (number specified by n_layers)\n",
    "        for _ in range(n_layers -1):\n",
    "            layers += [nn.Linear(hidden_dim, hidden_dim), nn.ReLU() ]\n",
    "\n",
    "        # Output Layer\n",
    "        layers += [nn.Linear(hidden_dim, output_dim)]\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the MLP.\n",
    "\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, input_dim).\n",
    "\n",
    "        Returns:\n",
    "            Tensor of shape (batch_size, output_dim) with class probabilities.\n",
    "        \"\"\"\n",
    "        x = self.network(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afd4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"\n",
    "    Utility class to keep track of running averages (e.g. loss during training).\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Current value, average, cumulative sum, and count.\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reset the class attributes.\n",
    "        \"\"\"\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n_count=1):\n",
    "        \"\"\"\n",
    "        Update the values.\n",
    "\n",
    "        Args:\n",
    "            val (float): Current value.\n",
    "            n_count (int, optional): Number of current value. Defaults to 1.\n",
    "        \"\"\"\n",
    "        self.val = val\n",
    "        self.sum += val * n_count\n",
    "        self.count += n_count\n",
    "        self.avg = self.sum / self.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model: nn.Module,\n",
    "          train_loader: DataLoader,\n",
    "          num_epochs: int,\n",
    "          criterion: nn.Module,\n",
    "          optimizer: optim.Optimizer,\n",
    "          device: torch.device\n",
    "          ) -> None:\n",
    "    \"\"\"\n",
    "    Simple training loop for a PyTorch model.\n",
    "\n",
    "    Args:\n",
    "        model: Model to train.\n",
    "        train_loader: DataLoader yielding (inputs, targets) batches.\n",
    "        num_epochs: Number of epochs to train.\n",
    "        criterion: Loss function.\n",
    "        optimizer: Optimizer (e.g. Adam).\n",
    "        device: Device on which to run the computation.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    loss_meter = AverageMeter()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            logits = model(x_batch)\n",
    "            # print(logits.shape, y_batch.shape)\n",
    "            loss = criterion(logits, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_meter.update(loss.item())\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | loss={loss_meter.avg:.3f}\")\n",
    "\n",
    "\n",
    "def predict(model: nn.Module,\n",
    "            test_loader: DataLoader,\n",
    "            device: torch.device\n",
    "            ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute class predictions for all samples in a DataLoader.\n",
    "\n",
    "    Args:\n",
    "        model: Trained model.\n",
    "        test_loader: DataLoader for the evaluation set.\n",
    "        device: Device on which to run inference.\n",
    "\n",
    "    Returns:\n",
    "        NumPy array of predicted class indices of shape (N,).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    # y_true = []\n",
    "    with torch.no_grad():\n",
    "        for batch_X, _ in test_loader:\n",
    "            preds = model(batch_X.to(device))\n",
    "            # preds = torch.sigmoid(logits)\n",
    "            predictions.append(preds.detach().cpu().numpy())\n",
    "\n",
    "            # y_true.append(batch_y.cpu().numpy())\n",
    "\n",
    "    probas = np.concatenate(predictions)\n",
    "\n",
    "    # If binary task returns only probability for the true class, adapt it to return (N x 2)\n",
    "    if probas.shape[1] == 1:\n",
    "        probas = np.concatenate((1 - probas, probas), 1)\n",
    "\n",
    "    predictions = np.argmax(probas, axis=1)\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b506188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model and training hyperparameters.\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_layers = 4\n",
    "input_dim = X_train_t.shape[1]\n",
    "hidden_dim = 47\n",
    "output_dim = 2 # number of classes\n",
    "num_epochs = 20\n",
    "lr = 1e-3\n",
    "\n",
    "model = MLPModel(n_layers=n_layers,\n",
    "                input_dim=input_dim,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=output_dim\n",
    "                ).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2d649e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the neural network.\n",
    "train(model,\n",
    "      train_loader=train_loader,\n",
    "      num_epochs=num_epochs,\n",
    "      criterion=criterion,\n",
    "      optimizer=optimizer,\n",
    "      device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fef89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set.\n",
    "pred = predict(model, test_loader, device)\n",
    "\n",
    "acc = (pred==y_test).mean()\n",
    "print(f\"Accuracy on the test set : {acc*100 :2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a399d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred, digits=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e0cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert predicted labels to a tensor (used later as \"target\" for some XAI methods).\n",
    "y_pred_t = torch.from_numpy(pred).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da412d",
   "metadata": {},
   "source": [
    "## Captum Attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78521331",
   "metadata": {},
   "source": [
    "We now use [Captum](https://captum.ai/) to compute gradient-based feature attributions for the MLP.\n",
    "We will:\n",
    "- Implement helper visualization utilities (global bar plots + beeswarm-style scatter).\n",
    "- Compute **Saliency**, **SmoothGrad**, **Input×Gradient**, and **Integrated Gradients**.\n",
    "- Compare them qualitatively and quantitatively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eed0bd0",
   "metadata": {},
   "source": [
    "### Visualization utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method to print importances and visualize distribution\n",
    "def visualize_importances(feature_names: List[str],\n",
    "                        importances: np.ndarray,\n",
    "                        title: str = \"Average Feature Importances\",\n",
    "                        plot: bool = True,\n",
    "                        axis_title: str = \"Features\"\n",
    "                        ) -> None:\n",
    "    \"\"\"\n",
    "    Print and optionally plot average feature importances.\n",
    "\n",
    "    Args:\n",
    "        feature_names: List of feature names (length = n_features).\n",
    "        importances: Array of importances of shape (n_features,).\n",
    "        title: Title for the plot/printout.\n",
    "        plot: If True, displays a bar plot using Matplotlib.\n",
    "        axis_title: Label for the x-axis.\n",
    "    \"\"\"\n",
    "    print(title)\n",
    "    for i in range(len(feature_names)):\n",
    "        print(feature_names[i], \": \", '%.4f'%(importances[i]))\n",
    "    x_pos = (np.arange(len(feature_names)))\n",
    "    if plot:\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.bar(x_pos, importances, align='center')\n",
    "        plt.xticks(x_pos, feature_names, wrap=True, rotation=45)\n",
    "        plt.xlabel(axis_title)\n",
    "        plt.title(title)\n",
    "\n",
    "\n",
    "def beeswarm_attributions(\n",
    "        attrs: np.ndarray,\n",
    "        X: np.ndarray,\n",
    "        feature_names: List[str],\n",
    "        max_display: int = 20,\n",
    "        color_by: str = \"feature\",\n",
    "        cmap=None,\n",
    "        jitter: float = 0.25,\n",
    "        dot_size: int = 8,\n",
    "        title: str = \"Beeswarm of Attributions\",\n",
    "        xlabel: str = \"Attribution (signed)\",\n",
    "):\n",
    "    \"\"\"\n",
    "    SHAP-style beeswarm plot for tabular attributions.\n",
    "\n",
    "    Args:\n",
    "        attrs: Array of shape (n_samples, n_features) with signed attributions.\n",
    "        X: Original input values (same shape as attrs).\n",
    "        feature_names: List of feature names.\n",
    "        max_display: Maximum number of features to display (sorted by mean |attr|).\n",
    "        color_by: Whether to color points by \"feature\" values, \"attr\" values, or None.\n",
    "        cmap: Matplotlib colormap name or object.\n",
    "        jitter: Vertical jitter scale to avoid overlap.\n",
    "        dot_size: Marker size.\n",
    "        title: Plot title.\n",
    "        xlabel: Label for the x-axis.\n",
    "    \"\"\"\n",
    "    attrs = np.asarray(attrs)\n",
    "    X = np.asarray(X)\n",
    "    assert attrs.shape == X.shape, \"attrs and X must have same shape [n_samples, n_features]\"\n",
    "    n_samples, n_features = attrs.shape\n",
    "    feature_names = list(feature_names)\n",
    "\n",
    "    # Rank features by mean absolute attribution\n",
    "    mean_abs = np.mean(np.abs(attrs), axis=0)\n",
    "    order = np.argsort(-mean_abs)[:max_display]\n",
    "    attrs_sub = attrs[:, order]\n",
    "    X_sub = X[:, order]\n",
    "    names_sub = [feature_names[i] for i in order]\n",
    "\n",
    "    # Prepare figure\n",
    "    plt.figure(figsize=(10, 0.4 * len(names_sub) + 2))\n",
    "    y_base = np.arange(len(names_sub))  # one row per feature (top is most important)\n",
    "    y_plot_positions = []\n",
    "\n",
    "    # Normalize color reference per-feature (like SHAP)\n",
    "    def normalize_col(v):\n",
    "        v = v.astype(float)\n",
    "        vmin, vmax = np.nanmin(v), np.nanmax(v)\n",
    "        if vmax == vmin:\n",
    "            return np.zeros_like(v)  # flat color if constant\n",
    "        return (v - vmin) / (vmax - vmin)\n",
    "\n",
    "    for j, (a_col, x_col) in enumerate(zip(attrs_sub.T, X_sub.T)):\n",
    "        # Jitter to avoid overplotting; more points near 0 should stack, not overlap\n",
    "        # Use rank-based spread to get a “swarm” feel\n",
    "        # We place points around y = (len(names_sub)-1 - j) so most important is at top\n",
    "        y0 = (len(names_sub) - 1 - j)\n",
    "        # Create a small symmetric jitter using ranks of attribution values\n",
    "        ranks = a_col.argsort().argsort()  # 0..n-1 ranks\n",
    "        # Center ranks around 0 and scale\n",
    "        jitter_offsets = (ranks - np.median(ranks)) / (np.max(ranks) + 1e-9)\n",
    "        y_vals = y0 + jitter * jitter_offsets\n",
    "        y_plot_positions.append(y0)\n",
    "\n",
    "        # Colors\n",
    "        if color_by == \"feature\":\n",
    "            cvals = normalize_col(x_col)\n",
    "            sc = plt.scatter(a_col, y_vals, s=dot_size, c=cvals, cmap=cmap, alpha=0.8, edgecolors='none')\n",
    "        elif color_by == \"attr\":\n",
    "            cvals = normalize_col(a_col)\n",
    "            sc = plt.scatter(a_col, y_vals, s=dot_size, c=cvals, cmap=cmap, alpha=0.8, edgecolors='none')\n",
    "        else:\n",
    "            sc = plt.scatter(a_col, y_vals, s=dot_size, alpha=0.8, edgecolors='none')\n",
    "\n",
    "    # Axes & labels\n",
    "    plt.yticks(np.arange(len(names_sub)), names_sub)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(axis='x', linestyle=':', alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Optional colorbar\n",
    "    if color_by in (\"feature\", \"attr\") and cmap is not None:\n",
    "        cbar = plt.colorbar(sc, pad=0.01)\n",
    "        cbar.set_label(\"Feature value\" if color_by == \"feature\" else \"Attribution (normalized)\")\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6654ac62",
   "metadata": {},
   "source": [
    "### Captum/Quantus metrics utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715b9ede",
   "metadata": {},
   "source": [
    "We use **Quantus** library which is an explainable AI toolit to evaluate neural network explanations.   \n",
    "A lot of XAI metrics including\n",
    "- Faithfulness metrics\n",
    "- Robustness metrics\n",
    "- Localisation and so on.\n",
    "\n",
    "Check the [Github repository](https://github.com/understandable-machine-intelligence-lab/Quantus/tree/main) for more details.\n",
    "\n",
    "In this lab, we will use two (02) faithfulness metrics: `Sufficiency` and `FaithfulnessEstimate` and three (03) robustness metrics: `RIS`, `ROS` and `Consistency`.\n",
    "\n",
    ">Note:\n",
    "Most of the metrics implemented in Quantus are compatible with **image datasets** and may not be applicable to tabular data. Check the documentation for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2657d6",
   "metadata": {},
   "source": [
    "We also include `Infidelity` and `Sensitivity` faithfulness metrics from **Captum** library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantus.AVAILABLE_METRICS['Faithfulness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f55c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quantus_metrics_multi(model: nn.Module,\n",
    "                              xai_wrappers: List[Callable],\n",
    "                              xai_names: List[str],\n",
    "                              x_data: np.ndarray,\n",
    "                              y_data: np.ndarray,\n",
    "                              device: torch.device,\n",
    "                              verbose: bool = True) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluates a model's XAI methods against a set of Quantus metrics.\n",
    "\n",
    "    Args:\n",
    "        model: The PyTorch model (nn.Module).\n",
    "        xai_wrappers: A list of Callable XAI explanation functions/wrappers.\n",
    "        xai_names: A list of strings corresponding to the names of the XAI methods.\n",
    "                   Must be the same length as xai_wrappers.\n",
    "        x_data: Input data batch (np.ndarray).\n",
    "        y_data: Target label batch (np.ndarray).\n",
    "        verbose: If True, prints evaluation details.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the evaluation results from quantus.evaluate.\n",
    "    \"\"\"\n",
    "    if len(xai_wrappers) != len(xai_names):\n",
    "        raise ValueError(\"The length of 'xai_wrappers' must match the length of 'xai_names'.\")\n",
    "\n",
    "    # Ensure model is in evaluation mode and on the correct device\n",
    "    model.eval().to(device)\n",
    "\n",
    "    # Define Quantus metrics\n",
    "    metrics = {\n",
    "        \"RIS\": quantus.RelativeInputStability(nr_samples=5),\n",
    "        \"ROS\": quantus.RelativeOutputStability(nr_samples=5),\n",
    "        \"Consistency\": quantus.Consistency(discretise_func=quantus.functions.discretise_func.top_n_sign,\n",
    "                                           return_aggregate=False),\n",
    "        \"Sufficiency\": quantus.Sufficiency(threshold=0.6,\n",
    "                                           return_aggregate=False),\n",
    "        \"Faithfulness\": quantus.FaithfulnessEstimate(abs=False,\n",
    "                                                     normalise=False,\n",
    "                                                     features_in_step=1,  \n",
    "                                                     perturb_baseline=\"mean\"),\n",
    "    }\n",
    "    \n",
    "    # Construct the XAI methods dictionary\n",
    "    # This uses a dictionary comprehension to map names to functions\n",
    "    xai_methods = dict(zip(xai_names, xai_wrappers))\n",
    "\n",
    "    # Quantus config \n",
    "    # explain_func_kwargs → required (even if empty)\n",
    "    explain_func_kwargs = {}\n",
    "\n",
    "    # call_kwargs for the metric\n",
    "    call_kwargs = {\"run\": {\"device\": device}}\n",
    "\n",
    "    # Evaluate\n",
    "    results = quantus.evaluate(\n",
    "        metrics=metrics,\n",
    "        xai_methods=xai_methods,\n",
    "        model=model,\n",
    "        x_batch=x_data,\n",
    "        y_batch=y_data,\n",
    "        explain_func_kwargs=explain_func_kwargs,\n",
    "        call_kwargs=call_kwargs,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906200e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics_results(results: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Extracts metric data from the first set of results, cleans it by\n",
    "    removing NaN values, and returns the cleaned data as a dictionary\n",
    "    of NumPy arrays.\n",
    "\n",
    "    Args:\n",
    "        results: A dictionary where the values are metric dictionaries\n",
    "                 (e.g., {'run_1': {'metric_a': [1, 2, np.nan], ...}}).\n",
    "\n",
    "    Returns:\n",
    "        A dictionary mapping metric names to their cleaned 1D NumPy arrays.\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        return {}\n",
    "\n",
    "    # Get the metric dictionary from the first result set\n",
    "    first_metrics_data = next(iter(results.values()))\n",
    "\n",
    "    # Process each metric in the first set\n",
    "    cleaned_metrics = {}\n",
    "    for metric_name, values_list in first_metrics_data.items():\n",
    "        metric_array = np.array(values_list, dtype=np.float64)\n",
    "\n",
    "        # Remove NaN values using Boolean indexing\n",
    "        #cleaned_array = metric_array[~np.isnan(metric_array)]\n",
    "        \n",
    "        #cleaned_metrics[metric_name] = cleaned_array\n",
    "        cleaned_metrics[metric_name] = metric_array\n",
    "    \n",
    "    return cleaned_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4a8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr._utils.attribution import GradientAttribution\n",
    "from captum.metrics import sensitivity_max, infidelity\n",
    "\n",
    "def get_captum_metrics(captum_attribution: GradientAttribution,\n",
    "                       inputs: torch.Tensor,\n",
    "                       target: torch.Tensor,\n",
    "                       attribution: torch.Tensor,\n",
    "                       device: torch.device) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Get Captum Sensitivity and Infidelity metrics.\n",
    "\n",
    "    Args:\n",
    "        captum_attribution (GradientAttribution): Captum attribution object.\n",
    "        inputs (torch.Tensor): Data features from which the attribution are computed.\n",
    "        target (torch.Tensor): Target predictions.\n",
    "        attribution (torch.Tensor): Captum attributions.\n",
    "        device (torch.device): Torch device.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: Sensitivity and Infidelity scores as nmpy array.\n",
    "    \"\"\"\n",
    "\n",
    "    def perturb_fn(inputs):\n",
    "        # Add small Gaussian noise and return noisy inputs and corresponding baseline.\n",
    "        noise = torch.tensor(np.random.normal(0, 0.003, inputs.shape)).to(inputs.device).float()\n",
    "        return noise, inputs - noise\n",
    "    \n",
    "    sens = sensitivity_max(captum_attribution.attribute,\n",
    "                           inputs.to(device),\n",
    "                           target=target.to(device)\n",
    "                           ).detach().cpu().numpy()\n",
    "\n",
    "    infid = infidelity(model, perturb_fn,\n",
    "                       inputs=inputs.to(device),\n",
    "                       attributions=attribution.to(device),\n",
    "                       target=target.to(device)\n",
    "                       ).detach().cpu().numpy()\n",
    "    return sens, infid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0111afc",
   "metadata": {},
   "source": [
    "### Saliency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ce2eda",
   "metadata": {},
   "source": [
    "A baseline approach for computing input attribution. It returns the gradients with respect to inputs. If abs is set to True, which is the default, the absolute value of the gradients is returned.\n",
    "\n",
    "More details about the approach can be found in the following paper:\n",
    "https://arxiv.org/abs/1312.6034"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42248c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the salience explainer with the forward function of the model.\n",
    "xai_saliency = Saliency(model)\n",
    "\n",
    "attr = xai_saliency.attribute(X_test_t.requires_grad_(True).to(device), # inputs for which explanations are computed \n",
    "                              target=y_pred_t, # Target\n",
    "                              abs=False \n",
    "                              )\n",
    "attr = attr.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b8afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize the attributions feature-wise (max absolute value = 1) to make\n",
    "# them easier to compare across features. (because Captum just return the gradients)\n",
    "\n",
    "eps = 1e-16\n",
    "denom = np.max(np.abs(attr), axis=0) + eps     # shape [n_features]\n",
    "attr_norm = attr / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d09b9a",
   "metadata": {},
   "source": [
    "#### Generate and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e631de4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from typing import Optional, Sequence, Tuple\n",
    "\n",
    "# def tabular_baseline_replacement_by_indices(\n",
    "#     arr: np.ndarray,                  # shape (N, F)\n",
    "#     indices: np.ndarray,              # shape (N, K) indices to replace per sample\n",
    "#     *,\n",
    "#     baselines: np.ndarray,            # shape (F,) per-feature baseline values\n",
    "#     ordinal_idx: Optional[Sequence[int]] = None,  # indices of ordinal features\n",
    "#     clip_bounds: Optional[Tuple[np.ndarray, np.ndarray]] = None,  # (mins, maxs), each shape (F,)\n",
    "#     round_ordinals: bool = True,\n",
    "#     perturb_baseline=None,\n",
    "# ) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     Replace selected features with feature-wise baselines.\n",
    "#     Optionally round ordinal features to integer codes and clip to valid ranges.\n",
    "#     \"\"\"\n",
    "#     out = arr.copy()\n",
    "#     N, F = out.shape\n",
    "#     if ordinal_idx is None:\n",
    "#         ordinal_idx = []\n",
    "#     ordinal_idx = np.asarray(ordinal_idx, dtype=int)\n",
    "\n",
    "#     for i in range(N):\n",
    "#         js = indices[i]  # features to replace for sample i\n",
    "#         out[i, js] = baselines[js]\n",
    "\n",
    "#         if len(ordinal_idx) and round_ordinals:\n",
    "#             # round only the ordinal columns that were touched\n",
    "#             touched_ord = np.intersect1d(js, ordinal_idx, assume_unique=False)\n",
    "#             if touched_ord.size:\n",
    "#                 out[i, touched_ord] = np.rint(out[i, touched_ord])\n",
    "\n",
    "#         if clip_bounds is not None:\n",
    "#             mins, maxs = clip_bounds\n",
    "#             out[i] = np.minimum(np.maximum(out[i], mins), maxs)\n",
    "\n",
    "#     return out\n",
    "\n",
    "\n",
    "# cat_cols_idx = X_df.columns.get_indexer(cat_cols)\n",
    "\n",
    "# # Continuous → mean; Ordinal → median (then round)\n",
    "# means = X_train[:, ~cat_cols_idx].mean(axis=0)\n",
    "# meds  = np.median(X_train[:, cat_cols_idx], axis=0)\n",
    "\n",
    "# baselines = np.empty(X_train.shape[1], dtype=float)\n",
    "# baselines[~cat_cols_idx] = means\n",
    "# baselines[ cat_cols_idx] = np.rint(meds)  # integer code for ordinal\n",
    "\n",
    "# ordinal_idx = np.where(cat_cols_idx)[0]\n",
    "\n",
    "# # Optional (but helpful): per-feature clip bounds from train set\n",
    "# mins = X_train.min(axis=0)\n",
    "# maxs = X_train.max(axis=0)\n",
    "# clip_bounds = (mins, maxs)\n",
    "\n",
    "# metric = quantus.FaithfulnessEstimate(\n",
    "#     features_in_step=1,           # ↑ → faster, ↓ → more resolution\n",
    "#     abs=False, normalise=False,   # start simple for tabular\n",
    "#     perturb_func=tabular_baseline_replacement_by_indices,\n",
    "#     perturb_func_kwargs={\n",
    "#         \"baselines\": baselines,\n",
    "#         \"ordinal_idx\": ordinal_idx,\n",
    "#         \"clip_bounds\": clip_bounds,\n",
    "#         \"round_ordinals\": True,\n",
    "#     },\n",
    "#     similarity_func=None,         # default Pearson is fine\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fe9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import quantus\n",
    "# from captum.attr import Saliency\n",
    "\n",
    "\n",
    "# # Wrap Captum's Saliency into a callable for Quantus.\n",
    "# model.eval().to(device)\n",
    "# xai_saliency = Saliency(model)\n",
    "\n",
    "# def saliency_explainer(model: nn.Module,\n",
    "#                        inputs: np.ndarray,\n",
    "#                        targets: np.ndarray,\n",
    "#                        **kwargs\n",
    "#                        ) -> np.ndarray:\n",
    "#     \"\"\"\n",
    "#     Wrapper around Captum's Saliency so it matches the interface expected by Quantus.\n",
    "\n",
    "#     Args:\n",
    "#         model: PyTorch model (not used explicitly, but required by Quantus).\n",
    "#         inputs: Input batch as NumPy array.\n",
    "#         targets: Class indices as NumPy array.\n",
    "\n",
    "#     Returns:\n",
    "#         Attributions as NumPy array of same shape as inputs.\n",
    "#     \"\"\"\n",
    "#     # Convert numpy -> torch\n",
    "#     x_t = torch.tensor(inputs, dtype=torch.float32, device=device, requires_grad=True)\n",
    "#     y_t = torch.tensor(targets, dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "#     # Compute attributions (Captum expects tensor inputs)\n",
    "#     attributions = xai_saliency.attribute(x_t, target=y_t, abs=False)\n",
    "#     return attributions.detach().cpu().numpy()\n",
    "\n",
    "# # --- 3. Metric and config\n",
    "# metrics = {\n",
    "#     \"RIS\": quantus.RelativeInputStability(nr_samples=5),\n",
    "#     \"ROS\": quantus.RelativeOutputStability(nr_samples=5),\n",
    "#     \"Consistency\": quantus.Consistency(discretise_func=quantus.functions.discretise_func.top_n_sign,\n",
    "#                                        return_aggregate=False,),\n",
    "#     \"Sufficiency\": quantus.Sufficiency(threshold=0.6,\n",
    "#                                        return_aggregate=False,\n",
    "#                                         ),\n",
    "#     \"Faithfulness\": quantus.FaithfulnessEstimate(abs=False,\n",
    "#                                                  normalise=False,\n",
    "#                                                 features_in_step=1,  \n",
    "#                                                 perturb_baseline=\"mean\",\n",
    "#                                                 ),\n",
    "# }\n",
    "\n",
    "# xai_methods = {\n",
    "#     \"Saliency\": saliency_explainer,  \n",
    "# }\n",
    "\n",
    "# # explain_func_kwargs → required (even if empty)\n",
    "# explain_func_kwargs = {}\n",
    "\n",
    "# # call_kwargs for the metric\n",
    "# call_kwargs = {\"run\": {\"device\": device}}\n",
    "\n",
    "# # --- 4. Evaluate\n",
    "# results = quantus.evaluate(\n",
    "#     metrics=metrics,\n",
    "#     xai_methods=xai_methods,\n",
    "#     model=model,\n",
    "#     x_batch=X_test[:100],  # numpy array\n",
    "#     y_batch=y_test[:100],  # numpy array\n",
    "#     #agg_func=np.mean,\n",
    "#     explain_func_kwargs=explain_func_kwargs,\n",
    "#     call_kwargs=call_kwargs,\n",
    "#     #return_as_df=True,\n",
    "#     verbose=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591e2edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from normalized saliency.\n",
    "visualize_importances(feature_names=feature_names_all,\n",
    "                      importances=np.mean(attr_norm, axis=0)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe81022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beeswarm-style visualization of saliency attributions.\n",
    "beeswarm_attributions(attrs=attr_norm,\n",
    "                      X=X_test,\n",
    "                      feature_names=feature_names_all,\n",
    "                      cmap=\"coolwarm\",\n",
    "                      color_by='attr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8148dfee",
   "metadata": {},
   "source": [
    "#### Compute explanations metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28db4ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_wrapper(model: nn.Module,\n",
    "                    inputs: np.ndarray,\n",
    "                    targets: np.ndarray,\n",
    "                    **kwargs\n",
    "                    ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Wrapper around Captum's Saliency so it matches the interface expected by Quantus.\n",
    "\n",
    "    Args:\n",
    "        model: PyTorch model (not used explicitly, but required by Quantus).\n",
    "        inputs: Input batch as NumPy array.\n",
    "        targets: Class indices as NumPy array.\n",
    "\n",
    "    Returns:\n",
    "        Attributions as NumPy array of same shape as inputs.\n",
    "    \"\"\"\n",
    "    # Convert numpy -> torch\n",
    "    x_t = torch.tensor(inputs, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    y_t = torch.tensor(targets, dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "    # Compute attributions (Captum expects tensor inputs)\n",
    "    attributions = xai_saliency.attribute(x_t, target=y_t, abs=False)\n",
    "    return attributions.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e64aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantus_metrics = get_quantus_metrics_multi(model=model,\n",
    "                                            xai_wrappers=[saliency_wrapper],\n",
    "                                            xai_names=[\"saliency\"],\n",
    "                                            x_data=X_test,\n",
    "                                            y_data=pred,\n",
    "                                            device=device,\n",
    "                                            verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "captum_metrics = get_captum_metrics(captum_attribution=xai_saliency,\n",
    "                                    inputs=X_test_t,\n",
    "                                    target=y_pred_t,\n",
    "                                    attribution=torch.from_numpy(attr),\n",
    "                                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af96b960",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = get_metrics_results(quantus_metrics)\n",
    "all_metrics[\"Sensitivity\"] = captum_metrics[0]\n",
    "all_metrics[\"Infidelity\"] = captum_metrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e81438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beware: RIS/ROS can produce NaN values for some samples.\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e3929",
   "metadata": {},
   "source": [
    "### SmoothGrad (NoiseTunnel over Saliency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bade1a8a",
   "metadata": {},
   "source": [
    "To implement **SmoothGrad**, we add gaussian noise using `NoiseTunnel` to each input in the batch nt_samples times and applies the `Saliency` attribution algorithm to each of the samples. The attributions of the samples are combined based on the given noise tunnel type (nt_type). Here we use `nt_type=\"smoothgrad\"`, and the mean of the sampled attributions is returned.\n",
    "\n",
    "More details can be find in this [paper](https://arxiv.org/abs/1706.03825).\n",
    "\n",
    "See [Captum documentation](https://captum.ai/api/noise_tunnel.html) to help for the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cfef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "xai_sg = NoiseTunnel(xai_saliency)\n",
    "attr = xai_sg.attribute(X_test_t.requires_grad_(True).to(device),\n",
    "                        target=y_pred_t,\n",
    "                        nt_type='smoothgrad',\n",
    "                        stdevs=0.1,\n",
    "                        nt_samples=10, # Lower this to reduce computational time\n",
    "                        abs=False)\n",
    "\n",
    "attr = attr.detach().cpu().numpy()\n",
    "\n",
    "# Normalize the attributions.\n",
    "\n",
    "eps = 1e-16\n",
    "denom = np.max(np.abs(attr), axis=0) + eps\n",
    "attr_norm = attr / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9638623",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db6887",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_importances(feature_names=feature_names_all,\n",
    "                      importances=np.mean(attr_norm, axis=0)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe16d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "beeswarm_attributions(attrs=attr_norm,\n",
    "                      X=X_test,\n",
    "                      feature_names=feature_names_all,\n",
    "                      cmap=\"coolwarm\",\n",
    "                      color_by='attr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3852ae90",
   "metadata": {},
   "source": [
    "#### Explanation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68dc997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothgrad_wrapper(model: nn.Module,\n",
    "                     inputs: np.ndarray,\n",
    "                     targets:np.ndarray,\n",
    "                     **kwargs\n",
    "                     ) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Wrapper around SmoothGrad (NoiseTunnel over Saliency) for Quantus.\n",
    "    \"\"\"\n",
    "    # Convert numpy -> torch\n",
    "    x_t = torch.tensor(inputs, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    y_t = torch.tensor(targets, dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "    # Compute attributions (Captum expects tensor inputs)\n",
    "    attributions = xai_sg.attribute(x_t,\n",
    "                        target=y_t,\n",
    "                        nt_type='smoothgrad',\n",
    "                        stdevs=0.1,\n",
    "                        nt_samples=10, # Lower this to reduce computational time\n",
    "                        abs=False)\n",
    "\n",
    "    return attributions.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44495d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantus_metrics = get_quantus_metrics_multi(model=model,\n",
    "                                            xai_wrappers=[smoothgrad_wrapper],\n",
    "                                            xai_names=[\"smoothgrad\"],\n",
    "                                            x_data=X_test[:10],\n",
    "                                            y_data=pred[:10], # The target\n",
    "                                            device=device,\n",
    "                                            verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1934879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "captum_metrics = get_captum_metrics(captum_attribution=xai_sg,\n",
    "                                    inputs=X_test_t,\n",
    "                                    target=y_pred_t,\n",
    "                                    attribution=torch.from_numpy(attr),\n",
    "                                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa74cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = get_metrics_results(quantus_metrics)\n",
    "all_metrics[\"Sensitivity\"] = captum_metrics[0]\n",
    "all_metrics[\"Infidelity\"] = captum_metrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55301824",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66743ce2",
   "metadata": {},
   "source": [
    "### Input x Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20dc93",
   "metadata": {},
   "source": [
    "A baseline approach for computing the attribution. It multiplies input with the gradient with respect to input. \n",
    "\n",
    "More details in the [paper](https://arxiv.org/abs/1605.01713).\n",
    "\n",
    "See [Captum documentation](https://captum.ai/api/input_x_gradient.html) to help for the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "xai_ig = InputXGradient(model)\n",
    "\n",
    "attr = xai_ig.attribute(X_test_t.requires_grad_(True).to(device),\n",
    "                        target=y_pred_t,\n",
    "                        )  # binary logit\n",
    "attr = attr.detach().cpu().numpy()\n",
    "\n",
    "# Normalize the attributions.\n",
    "\n",
    "eps = 1e-16\n",
    "denom = np.max(np.abs(attr), axis=0) + eps     # shape [n_features]\n",
    "attr_norm = attr / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97626a7",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db1bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_importances(feature_names=feature_names_all,\n",
    "                      importances=np.mean(attr_norm, axis=0)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f87ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "beeswarm_attributions(attrs=attr_norm,\n",
    "                      X=X_test,\n",
    "                      feature_names=feature_names_all,\n",
    "                      cmap=\"coolwarm\",\n",
    "                      color_by='attr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cb1539",
   "metadata": {},
   "source": [
    "#### Explanation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc76022",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_grad_wrapper(model, inputs, targets, **kwargs):\n",
    "    # Convert numpy -> torch\n",
    "    x_t = torch.tensor(inputs, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    y_t = torch.tensor(targets, dtype=torch.long, device=device)\n",
    "\n",
    "\n",
    "    attributions = xai_ig.attribute(x_t,\n",
    "                                    target=y_t,\n",
    "                                    )\n",
    "    return attributions.detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02853e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantus_metrics = get_quantus_metrics_multi(model=model,\n",
    "                                            xai_wrappers=[inp_grad_wrapper],\n",
    "                                            xai_names=[\"inputgrad\"],\n",
    "                                            x_data=X_test[:10],\n",
    "                                            y_data=pred[:10], # The target\n",
    "                                            device=device,\n",
    "                                            verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d7f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "captum_metrics = get_captum_metrics(captum_attribution=xai_ig,\n",
    "                                    inputs=X_test_t[:10],\n",
    "                                    target=y_pred_t[:10],\n",
    "                                    attribution=torch.from_numpy(attr)[:10],\n",
    "                                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b26291",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = get_metrics_results(quantus_metrics)\n",
    "all_metrics[\"Sensitivity\"] = captum_metrics[0]\n",
    "all_metrics[\"Infidelity\"] = captum_metrics[1]\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9123c7c4",
   "metadata": {},
   "source": [
    "### Integrated Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20b50da",
   "metadata": {},
   "source": [
    "Integrated Gradients is an axiomatic model interpretability algorithm that assigns an importance score to each input feature by approximating the integral of gradients of the model’s output with respect to the inputs along the path (straight line) from given baselines / references to inputs.\n",
    "\n",
    "More details regarding the integrated gradients method can be found in the original [paper](https://arxiv.org/abs/1703.01365)\n",
    "\n",
    "See [Captum documentation](https://captum.ai/api/integrated_gradients.html) to help for the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f571e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xai_int_grad = IntegratedGradients(model)\n",
    "baseline = X_train_t.mean(dim=0) # Take on input (as the mean of the training set)\n",
    "baselines = baseline.repeat(X_test_t.shape[0], 1).to(device) # Cast to the shape of the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de0c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = xai_int_grad.attribute(X_test_t.requires_grad_(True).to(device),\n",
    "                        target=y_pred_t,\n",
    "                        baselines=baselines,\n",
    "                        n_steps=50\n",
    "                        )\n",
    "attr = attr.detach().cpu().numpy()\n",
    "\n",
    "# Normalize the attributions (because Captum just return the gradients)\n",
    "eps = 1e-16\n",
    "denom = np.max(np.abs(attr), axis=0) + eps     # shape [n_features]\n",
    "attr_norm = attr / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38257b1",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0046879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_importances(feature_names=feature_names_all,\n",
    "                      importances=np.mean(attr_norm, axis=0)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5193df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "beeswarm_attributions(attrs=attr_norm,\n",
    "                      X=X_test,\n",
    "                      feature_names=feature_names_all,\n",
    "                      cmap=\"coolwarm\",\n",
    "                      color_by='attr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8f345",
   "metadata": {},
   "source": [
    "#### Explanation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80f2e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intgrad_wrapper(model, inputs, targets, **kwargs):\n",
    "\n",
    "    # Convert numpy -> torch\n",
    "    x_t = torch.tensor(inputs, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    y_t = torch.tensor(targets, dtype=torch.long, device=device)\n",
    "    baseline = X_train_t.mean(dim=0)\n",
    "    baselines = baseline.repeat(x_t.shape[0], 1).to(device) # Cast to the shape of the test set\n",
    "\n",
    "    attributions = xai_int_grad.attribute(x_t,\n",
    "                        target=y_t,\n",
    "                        baselines=baselines,\n",
    "                        n_steps=50\n",
    "                        )\n",
    "    return attributions.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaef2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantus_metrics = get_quantus_metrics_multi(model=model,\n",
    "                                            xai_wrappers=[intgrad_wrapper],\n",
    "                                            xai_names=[\"integrated_gradients\"],\n",
    "                                            x_data=X_test[:10],\n",
    "                                            y_data=pred[:10], # The target\n",
    "                                            device=device,\n",
    "                                            verbose= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31056723",
   "metadata": {},
   "outputs": [],
   "source": [
    "captum_metrics = get_captum_metrics(captum_attribution=xai_int_grad,\n",
    "                                    inputs=X_test_t[:10],\n",
    "                                    target=y_pred_t[:10],\n",
    "                                    attribution=torch.from_numpy(attr)[:10],\n",
    "                                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17555a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = get_metrics_results(quantus_metrics)\n",
    "all_metrics[\"Sensitivity\"] = captum_metrics[0]\n",
    "all_metrics[\"Infidelity\"] = captum_metrics[1]\n",
    "all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aada00c5",
   "metadata": {},
   "source": [
    "### LRP (Layer-wise Relevance Propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d605c5",
   "metadata": {},
   "source": [
    "Layer-wise relevance propagation is based on a backward propagation mechanism applied sequentially to all layers of the model. Here, the model output score represents the initial relevance which is decomposed into values for each neuron of the underlying layers. The decomposition is defined by rules that are chosen for each layer, involving its weights and activations. Details on the model can be found in the [original paper](https://doi.org/10.1371/journal.pone.0130140).\n",
    "\n",
    "We could use LRP implementation of Captum but we will choose [**Zennit library**](https://zennit.readthedocs.io/en/latest/getting-started.html) that is more complete and extensible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660b9c32",
   "metadata": {},
   "source": [
    "We use `EpsilonPlus` composite, which uses `ZPlus` rule (LRP rule that only takes positive contributions) for convolutional layers and `Epsilon` rule (the most basic LRP rule) for densely connected linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f2a9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zennit.composites import EpsilonPlus\n",
    "\n",
    "\n",
    "# Create a composite instance (choice of propagation rules).\n",
    "composite = EpsilonPlus()\n",
    "xai_lrp_grad = Gradient(model, composite)\n",
    "\n",
    "# Targets as one-hot vectors for each predicted class.\n",
    "targets = torch.nn.functional.one_hot(y_pred_t, num_classes=2).float()\n",
    "\n",
    "# Make sure the input requires a gradient.\n",
    "\n",
    "with xai_lrp_grad:\n",
    "     # gradient/ relevance wrt. output/class\n",
    "     output, attr = xai_lrp_grad(X_test_t.requires_grad_(True).to(device),\n",
    "                                 targets\n",
    "                                 )\n",
    "\n",
    "attr = attr.detach().cpu().numpy()\n",
    "\n",
    "# Normalize the attributions (because Captum just return the gradients)\n",
    "\n",
    "eps = 1e-16\n",
    "denom = np.max(np.abs(attr), axis=0) + eps     # shape [n_features]\n",
    "attr_norm = attr / denom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3bd31",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ac9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_importances(feature_names=feature_names_all,\n",
    "                      importances=np.mean(attr_norm, axis=0)\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45838797",
   "metadata": {},
   "outputs": [],
   "source": [
    "beeswarm_attributions(attrs=attr_norm,\n",
    "                      X=X_test,\n",
    "                      feature_names=feature_names_all,\n",
    "                      cmap=\"coolwarm\",\n",
    "                      color_by='attr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e6588",
   "metadata": {},
   "source": [
    "#### Explanation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32efca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrp_wrapper(model, inputs, targets, **kwargs):\n",
    "    # Convert numpy -> torch\n",
    "    x_t = torch.tensor(inputs, dtype=torch.float32, device=device, requires_grad=True)\n",
    "    y_t = torch.tensor(targets, dtype=torch.long, device=device)\n",
    "    y_t = torch.nn.functional.one_hot(y_t, num_classes=2).float()\n",
    "\n",
    "\n",
    "    with xai_lrp_grad:\n",
    "     # gradient/ relevance wrt. output/class 1\n",
    "     _, attributions = xai_lrp_grad(x_t,\n",
    "                            y_t\n",
    "                            )\n",
    "     return attributions.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b2abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantus_metrics = get_quantus_metrics_multi(model=model,\n",
    "                                            xai_wrappers=[lrp_wrapper],\n",
    "                                            xai_names=[\"lrp\"],\n",
    "                                            x_data=X_test[:10],\n",
    "                                            y_data=pred[:10], # The target\n",
    "                                            device=device,\n",
    "                                            verbose= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06a00b0",
   "metadata": {},
   "source": [
    "Captum metrics do not work with Zennit LRP.\n",
    "You could restart this subsection with Captum LRP.\n",
    "See the [documentation](https://captum.ai/api/lrp.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cdd4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# captum_metrics = get_captum_metrics(captum_attribution=xai_lrp_grad,\n",
    "#                                     inputs=X_test_t,\n",
    "#                                     target=y_pred_t,\n",
    "#                                     attribution=torch.from_numpy(attr),\n",
    "#                                     device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa9a0a0",
   "metadata": {},
   "source": [
    "## Counterfactuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599b2bf",
   "metadata": {},
   "source": [
    "### DiCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee4c4ad",
   "metadata": {},
   "source": [
    "We now switch to counterfactual examples using the Adult dataset.\n",
    "\n",
    "For that, we will use one of the most common methods for counterfactuals generation, **DiCE** inspired from this paper: [Explaining Machine Learning Classifiers through Diverse\n",
    "Counterfactual Explanations](https://arxiv.org/pdf/1905.07697).\n",
    "\n",
    "This section is inspired from the official documentation of DiCE. Check it for more details: [DiCE package](https://interpret.ml/DiCE/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb54bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dice_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1668d1",
   "metadata": {},
   "source": [
    "Re-load the Adult dataset (here we keep it separate to keep the DiCE pipeline self-contained).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b99e0bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Adult from OpenML\n",
    "adult = fetch_openml(name='adult', version=2, as_frame=True)\n",
    "df = adult.frame.copy()\n",
    "\n",
    "# Replace '?' with NaN and drop rows with missing (simple approach)\n",
    "df = df.replace('?', np.nan).dropna()\n",
    "\n",
    "# Target is 'class': '>50K' or '<=50K' — convert to 0/1\n",
    "df['class'] = (df['class'] == '>50K').astype(int)\n",
    "\n",
    "\n",
    "# Identify categorical vs numeric columns\n",
    "target_col = 'class'\n",
    "y = df[target_col].values\n",
    "\n",
    "\n",
    "# Split into train test\n",
    "train_dataset, test_dataset, y_train, y_test = train_test_split(\n",
    "    df, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "X_train = train_dataset.drop(columns=[target_col])\n",
    "X_test = test_dataset.drop(columns=[target_col])\n",
    "\n",
    "cat_cols = X_train.select_dtypes(include=['category','object']).columns.tolist()\n",
    "num_cols = [c for c in X_train.columns if c not in cat_cols]\n",
    "\n",
    "categorical_feature_name = X_train.select_dtypes(include=['category','object']).columns.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e25806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build preprocessing pipeline: OrdinalEncoder for categoricals, Standardize numerics\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        # ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
    "        ('cat', OrdinalEncoder(), categorical_feature_name), # We use here OrdinalEncoder to limit the number of features\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Full sklearn pipeline = preprocessing + RandomForest.\n",
    "clf = Pipeline(steps=[('preprocessor', preprocess),\n",
    "                      ('classifier', RandomForestClassifier())\n",
    "                      ])\n",
    "\n",
    "# Train the model\n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad322208",
   "metadata": {},
   "source": [
    "We now initialize the DiCE explainer, which needs a dataset and a model. DiCE provides local explanation for the model m and requires an query input whose outcome needs to be explained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b68b1",
   "metadata": {},
   "source": [
    "DiCE supports *sklearn*, *tensorflow* and *pytorch* models.\n",
    "\n",
    "The variable backend below indicates the implementation type of DiCE we want to use. Four backends are supported: sklearn, TensorFlow 1.x with `backend=’TF1’`, Tensorflow 2.x with `backend=’TF2’`, and PyTorch with `backend=’PYT’`.\n",
    "\n",
    "Here, we use a trained classification model using sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b28c004",
   "metadata": {},
   "source": [
    "Given the train dataset, we construct a *data object* for DiCE. Since continuous and discrete features have different ways of perturbation, we need to specify the names of the continuous features. DiCE also requires the name of the output variable that the ML model will predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca8dc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "d = dice_ml.Data(dataframe=df,\n",
    "                continuous_features=num_cols,\n",
    "                outcome_name='class')\n",
    "\n",
    "# Using sklearn backend\n",
    "m = dice_ml.Model(model=model,\n",
    "                  backend=\"sklearn\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6871f79b",
   "metadata": {},
   "source": [
    "The `method` parameter specifies the explanation method. DiCE supports three methods for sklearn models:    \n",
    "    - `random` sampling,   \n",
    "    - `genetic` algorithm search: [GeCo: Quality Counterfactual Explanations in Real Time](https://arxiv.org/pdf/2101.01292)   \n",
    "    - `kd-tree` based generation: [Interpretable Counterfactual Explanations Guided by Prototypes](https://arxiv.org/pdf/1907.02584)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecabdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using method=random for generating CFs\n",
    "exp = dice_ml.Dice(d, m, method=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e50ccc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>62857</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education-num      marital-status  \\\n",
       "0   43   Private   62857  Some-college             10  Married-civ-spouse   \n",
       "\n",
       "     occupation relationship   race   sex  capital-gain  capital-loss  \\\n",
       "0  Craft-repair      Husband  White  Male             0             0   \n",
       "\n",
       "   hours-per-week native-country  class  \n",
       "0              60  United-States      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>77248</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>-</td>\n",
       "      <td>96490</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age workclass fnlwgt education education-num marital-status occupation  \\\n",
       "0   -         -      -         -             -              -          -   \n",
       "1   -         -      -         -             -              -          -   \n",
       "\n",
       "  relationship                race sex capital-gain capital-loss  \\\n",
       "0            -                   -   -        77248            -   \n",
       "1            -  Asian-Pac-Islander   -        96490            -   \n",
       "\n",
       "  hours-per-week native-country class  \n",
       "0              -              -     1  \n",
       "1              -              -     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_instance = X_test.iloc[0:1]\n",
    "\n",
    "# Generate counterfactuals\n",
    "e1 = exp.generate_counterfactuals(query_instance,\n",
    "                                  total_CFs=2,\n",
    "                                  desired_class=\"opposite\")\n",
    "\n",
    "# Visualization\n",
    "e1.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb0ba02",
   "metadata": {},
   "source": [
    "> **Try**:\n",
    "- Changing `query_instance` to other rows.\n",
    "- Changing the `method` use for DiCE.\n",
    "- Increasing `total_CFs`.\n",
    "- Inspecting which features change most often."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21175594",
   "metadata": {},
   "source": [
    "You can try generating counterfactual explanations for other examples using the same code. It is also possible to restrict the features to vary while generating the counterfactuals with the argument `features_to_vary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8fc8296f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>62857</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education-num      marital-status  \\\n",
       "0   43   Private   62857  Some-college             10  Married-civ-spouse   \n",
       "\n",
       "     occupation relationship   race   sex  capital-gain  capital-loss  \\\n",
       "0  Craft-repair      Husband  White  Male             0             0   \n",
       "\n",
       "   hours-per-week native-country  class  \n",
       "0              60  United-States      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Preschool</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Sales</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age workclass fnlwgt  education education-num marital-status  \\\n",
       "0   -         -      -  Preschool             -              -   \n",
       "1   -         -      -  Doctorate             -              -   \n",
       "\n",
       "        occupation relationship race sex capital-gain capital-loss  \\\n",
       "0            Sales            -    -   -            -            -   \n",
       "1  Exec-managerial            -    -   -            -            -   \n",
       "\n",
       "  hours-per-week native-country class  \n",
       "0              -              -     -  \n",
       "1              -              -     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Changing only age and education\n",
    "e2 = exp.generate_counterfactuals(query_instance,\n",
    "                                  total_CFs=2,\n",
    "                                  desired_class=\"opposite\",\n",
    "                                  features_to_vary=[\"education\", \"occupation\"]\n",
    "                                  )\n",
    "e2.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03df35f",
   "metadata": {},
   "source": [
    "It is also possible to specify permitted range of features within which the counterfactual should be generated with `permitted_range`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ef2f56b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>62857</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age workclass  fnlwgt     education  education-num      marital-status  \\\n",
       "0   43   Private   62857  Some-college             10  Married-civ-spouse   \n",
       "\n",
       "     occupation relationship   race   sex  capital-gain  capital-loss  \\\n",
       "0  Craft-repair      Husband  White  Male             0             0   \n",
       "\n",
       "   hours-per-week native-country  class  \n",
       "0              60  United-States      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Diverse Counterfactual set (new outcome: 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age workclass fnlwgt education education-num marital-status occupation  \\\n",
       "0   -         -      -         -             -              -          -   \n",
       "1   -         -      -         -             -              -          -   \n",
       "\n",
       "     relationship race sex capital-gain capital-loss hours-per-week  \\\n",
       "0  Other-relative    -   -            -            -              -   \n",
       "1               -    -   -            -            -              -   \n",
       "\n",
       "  native-country class  \n",
       "0              -     1  \n",
       "1              -     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Restricting age to be between [20,30] and Education to be either {'Doctorate', 'Prof-school'}.\n",
    "e3 = exp.generate_counterfactuals(query_instance,\n",
    "                                  total_CFs=2,\n",
    "                                  desired_class=\"opposite\",\n",
    "                                  permitted_range={'age': [20, 30], 'education': ['Doctorate', 'Prof-school']})\n",
    "e3.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47300674",
   "metadata": {},
   "source": [
    "## Attacks on LIME and SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4e9798",
   "metadata": {},
   "source": [
    "In this final section, we build adversarial models that:\n",
    "- behave like a biased model `f` (e.g. depending explicitly on a sensitive feature),\n",
    "- but appear innocent to explanations from LIME/SHAP by mimicking another model $\\phi$.\n",
    "\n",
    "This demonstrates that **post-hoc explanations can be fooled**.\n",
    "\n",
    "This attack was proposed by Slack et al. [Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods](https://arxiv.org/abs/1911.02508)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9aadf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Adult from OpenML\n",
    "adult = fetch_openml(name='adult', version=2, as_frame=True)\n",
    "df = adult.frame.copy()\n",
    "\n",
    "# Replace '?' with NaN and drop rows with missing (simple approach)\n",
    "df = df.replace('?', np.nan).dropna()\n",
    "\n",
    "# Target is 'class': '>50K' or '<=50K' — convert to 0/1\n",
    "df['class'] = (df['class'] == '>50K').astype(int)\n",
    "\n",
    "# Add a random column -- this is what we'll have LIME/SHAP explain.\n",
    "df['unrelated_column'] = np.random.choice([0,1],size=df.shape[0])\n",
    "\n",
    "# Identify categorical vs numeric columns\n",
    "target_col = 'class'\n",
    "X_df = df.drop(columns=[target_col])\n",
    "y = df[target_col].values\n",
    "\n",
    "categorical_feature_name = X_df.select_dtypes(include=['category','object']).columns.tolist()\n",
    "categorical_feature_name += [\"unrelated_column\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93699148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build preprocessing pipeline: OrdinalEncoder for categoricals, Standardize numerics\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_cols),\n",
    "        # ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
    "        ('cat', OrdinalEncoder(), categorical_feature_name), # We use here OrdinalEncoder to limit the number of features\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_processed = preprocess.fit_transform(X_df)\n",
    "feature_names_num = num_cols\n",
    "feature_names_cat = list(preprocess.named_transformers_['cat'].get_feature_names_out(categorical_feature_name))\n",
    "feature_names_all = feature_names_num + feature_names_cat\n",
    "\n",
    "categorical_feature_indcs = [feature_names_all.index(cat) for cat in feature_names_cat if cat in feature_names_all]\n",
    "\n",
    "\n",
    "# Split into train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_processed, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the encoded indices of specific features.\n",
    "sex_indc = feature_names_all.index('sex')\n",
    "unrelated_indcs = feature_names_all.index('unrelated_column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f58e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which outcome is positive (income > 50K) or not (income < 50K).\n",
    "negative_outcome = 0\n",
    "positive_outcome = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c77d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y):\n",
    "    \"\"\" One hot encode y for binary features.  We use this to get from 1 dim ys to predict proba's.\n",
    "    This is taken from this s.o. post: https://stackoverflow.com/questions/29831489/convert-array-of-indices-to-1-hot-encoded-numpy-array\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : np.ndarray\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    A np.ndarray of the one hot encoded data.\n",
    "    \"\"\"\n",
    "    y_hat_one_hot = np.zeros((len(y), 2))\n",
    "    y_hat_one_hot[np.arange(len(y)), y] = 1\n",
    "    return y_hat_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa686eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sexist_model_f:\n",
    "    \"\"\"\n",
    "    Simple \"biased\" model: prediction depends solely on the encoded sex feature.\n",
    "\n",
    "    This is intentionally unrealistic but serves as a toy example of an unfair classifier.\n",
    "    \"\"\"\n",
    "    # Decision rule: classify negatively if race is woman\n",
    "    def predict(self, X):\n",
    "        return np.array([negative_outcome if x[sex_indc] == 0 else positive_outcome for x in X])\n",
    "\n",
    "    def predict_proba(self, X): \n",
    "        return one_hot_encode(self.predict(X))\n",
    "\n",
    "    def score(self, X,y):\n",
    "        return np.sum(self.predict(X)==y) / len(X)\n",
    "    \n",
    "class innocuous_model_psi:\n",
    "    \"\"\"\n",
    "    Innocuous-looking model: predicts according to the random 'unrelated_column'.\n",
    "\n",
    "    This is the model we will pretend to be for explanation methods.\n",
    "    \"\"\"\n",
    "    # Decision rule: classify according to randomly drawn column 'unrelated column'\n",
    "    def predict(self,X):\n",
    "        return np.array([negative_outcome if x[unrelated_indcs] > 0 else positive_outcome for x in X])\n",
    "\n",
    "    def predict_proba(self, X): \n",
    "        return one_hot_encode(self.predict(X))\n",
    "\n",
    "    def score(self, X,y):\n",
    "        return np.sum(self.predict(X)==y) / len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecb28ab",
   "metadata": {},
   "source": [
    "### Fooling LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbe4887",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fooling_lime_shap import Adversarial_Lime_Model\n",
    "\n",
    "# Train the adversarial model for LIME with f and psi \n",
    "adv_lime = Adversarial_Lime_Model(\n",
    "    sexist_model_f(),\n",
    "    innocuous_model_psi()).train(X_train[:100],\n",
    "                                 y_train[:100],\n",
    "                                 feature_names=feature_names_all,\n",
    "                                 categorical_features=categorical_feature_indcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1892ddd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Let's just look at a random example in the test set\n",
    "ex_indc = np.random.choice(X_test.shape[0])\n",
    "\n",
    "# To get a baseline, we'll look at LIME applied to the biased model f\n",
    "normal_explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names=adv_lime.get_column_names(),\n",
    "                                                          discretize_continuous=False,\n",
    "                                                          categorical_features=categorical_feature_indcs)\n",
    "\n",
    "normal_exp = normal_explainer.explain_instance(X_test[ex_indc], sexist_model_f().predict_proba)\n",
    "\n",
    "# Visualization of LIME explanation of the biased model.\n",
    "html = normal_exp.as_html()\n",
    "display(HTML(html))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e62cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets look at the explanations on the adversarial model \n",
    "adv_explainer = lime.lime_tabular.LimeTabularExplainer(X_train,feature_names=adv_lime.get_column_names(), \n",
    "                                                       discretize_continuous=False,\n",
    "                                                       categorical_features=categorical_feature_indcs)\n",
    "\n",
    "adv_exp = adv_explainer.explain_instance(X_test[ex_indc], adv_lime.predict_proba)\n",
    "\n",
    "# Visualization of LIME explanation of the adversarial model.\n",
    "html = adv_exp.as_html()\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b3f326",
   "metadata": {},
   "source": [
    "### Fooling SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f07cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fooling_lime_shap import Adversarial_Kernel_SHAP_Model\n",
    "\n",
    "\n",
    "# Train the adversarial model\n",
    "adv_shap = Adversarial_Kernel_SHAP_Model(sexist_model_f(), innocuous_model_psi()).\\\n",
    "            train(X_train[:100], y_train[:100], feature_names=feature_names_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa1a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Set the background distribution for the shap explainer using kmeans\n",
    "# The results get better if we use a lot of samples but at the expense\n",
    "# of a longer training time\n",
    "background_distribution = shap.kmeans(X_train, 100)\n",
    "\n",
    "# Let's use the shap kernel explainer and grab a point to explain\n",
    "to_examine = np.random.choice(X_test.shape[0])\n",
    "\n",
    "# Explain the biased model\n",
    "biased_kernel_explainer = shap.KernelExplainer(sexist_model_f().predict, background_distribution)\n",
    "biased_shap_values = biased_kernel_explainer.shap_values(X_test[to_examine:to_examine+1])\n",
    "\n",
    "# Explain the adversarial model\n",
    "adv_kerenel_explainer = shap.KernelExplainer(adv_shap.predict, background_distribution)\n",
    "adv_shap_values = adv_kerenel_explainer.shap_values(X_test[to_examine:to_examine+1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35a06e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SHAP values for the biased model.\n",
    "shap.summary_plot(biased_shap_values,\n",
    "                  feature_names=feature_names_all,\n",
    "                  plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot SHAP values for the biased model.\n",
    "shap.summary_plot(adv_shap_values,\n",
    "                  feature_names=feature_names_all,\n",
    "                  plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9a8b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "0x_xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
